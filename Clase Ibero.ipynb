{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d4983d2-9159-47d2-8aba-9ddbab41522c",
   "metadata": {},
   "source": [
    "# Clase Noviembre 4, 2025"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ae18d4-c31a-44a2-a3e4-8653f04db82d",
   "metadata": {},
   "source": [
    "Hoy vamos a descargar fotos de google street view y analizarlas para obtener:\n",
    "- Objetos (Modelo YOLOv8)\n",
    "- Porcentaje de verde\n",
    "- Textura con gradiente\n",
    "- Embeddings visuales (Modelo ResNet 18)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c08c926-a8e1-4fba-a6b5-e2d1fc845329",
   "metadata": {},
   "source": [
    "## Paso 1: Obtener API\n",
    "- Generar cuenta en https://console.cloud.google.com/\n",
    "- Crear API restringida para Google Street View\n",
    "- Guardar API en notepad en carpeta con nombre \"GoogleCloud\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "985da394-89d8-4647-92d0-49f158b36c47",
   "metadata": {},
   "source": [
    "## Paso 2: Obtener PanoID de lugares seleccionados\n",
    "- Localizar coordenadas geogr√°ficas de cinco lugares\n",
    "- Crear archivo excel con\n",
    "    - Identificador de la foto: ID\n",
    "    - Latitud: lat\n",
    "    - Longitud: lon\n",
    "- Descargar notebook con funciones para buscar y analizar imagenes de https://github.com/IreneZMo/Clase-Ibero\n",
    "    - Guardar archivo en la misma carpeta de trabajo\n",
    "- Empezamos a programar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28d0483f-44bc-454e-ac16-7cf502b34794",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\irene\\anaconda3\\lib\\site-packages (2.8.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\irene\\anaconda3\\lib\\site-packages (from torch) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\irene\\anaconda3\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\irene\\anaconda3\\lib\\site-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx in c:\\users\\irene\\anaconda3\\lib\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\irene\\anaconda3\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\irene\\anaconda3\\lib\\site-packages (from torch) (2025.3.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\irene\\anaconda3\\lib\\site-packages (from torch) (80.9.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\irene\\anaconda3\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\irene\\anaconda3\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\irene\\anaconda3\\lib\\site-packages (4.12.0.88)\n",
      "Requirement already satisfied: numpy<2.3.0,>=2 in c:\\users\\irene\\anaconda3\\lib\\site-packages (from opencv-python) (2.2.6)\n",
      "Requirement already satisfied: geopandas in c:\\users\\irene\\anaconda3\\lib\\site-packages (1.1.1)\n",
      "Requirement already satisfied: numpy>=1.24 in c:\\users\\irene\\anaconda3\\lib\\site-packages (from geopandas) (2.2.6)\n",
      "Requirement already satisfied: pyogrio>=0.7.2 in c:\\users\\irene\\anaconda3\\lib\\site-packages (from geopandas) (0.11.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\irene\\anaconda3\\lib\\site-packages (from geopandas) (24.2)\n",
      "Requirement already satisfied: pandas>=2.0.0 in c:\\users\\irene\\anaconda3\\lib\\site-packages (from geopandas) (2.2.3)\n",
      "Requirement already satisfied: pyproj>=3.5.0 in c:\\users\\irene\\anaconda3\\lib\\site-packages (from geopandas) (3.7.2)\n",
      "Requirement already satisfied: shapely>=2.0.0 in c:\\users\\irene\\anaconda3\\lib\\site-packages (from geopandas) (2.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\irene\\anaconda3\\lib\\site-packages (from pandas>=2.0.0->geopandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\irene\\anaconda3\\lib\\site-packages (from pandas>=2.0.0->geopandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\irene\\anaconda3\\lib\\site-packages (from pandas>=2.0.0->geopandas) (2025.2)\n",
      "Requirement already satisfied: certifi in c:\\users\\irene\\anaconda3\\lib\\site-packages (from pyogrio>=0.7.2->geopandas) (2025.10.5)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\irene\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=2.0.0->geopandas) (1.17.0)\n",
      "Requirement already satisfied: ultralytics in c:\\users\\irene\\anaconda3\\lib\\site-packages (8.3.204)\n",
      "Requirement already satisfied: numpy>=1.23.0 in c:\\users\\irene\\anaconda3\\lib\\site-packages (from ultralytics) (2.2.6)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in c:\\users\\irene\\anaconda3\\lib\\site-packages (from ultralytics) (3.10.0)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in c:\\users\\irene\\anaconda3\\lib\\site-packages (from ultralytics) (4.12.0.88)\n",
      "Requirement already satisfied: pillow>=7.1.2 in c:\\users\\irene\\anaconda3\\lib\\site-packages (from ultralytics) (11.1.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in c:\\users\\irene\\anaconda3\\lib\\site-packages (from ultralytics) (6.0.2)\n",
      "Requirement already satisfied: requests>=2.23.0 in c:\\users\\irene\\anaconda3\\lib\\site-packages (from ultralytics) (2.32.3)\n",
      "Requirement already satisfied: scipy>=1.4.1 in c:\\users\\irene\\anaconda3\\lib\\site-packages (from ultralytics) (1.16.2)\n",
      "Requirement already satisfied: torch>=1.8.0 in c:\\users\\irene\\anaconda3\\lib\\site-packages (from ultralytics) (2.8.0)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in c:\\users\\irene\\anaconda3\\lib\\site-packages (from ultralytics) (0.23.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\irene\\anaconda3\\lib\\site-packages (from ultralytics) (5.9.0)\n",
      "Requirement already satisfied: polars in c:\\users\\irene\\anaconda3\\lib\\site-packages (from ultralytics) (1.33.1)\n",
      "Requirement already satisfied: ultralytics-thop>=2.0.0 in c:\\users\\irene\\anaconda3\\lib\\site-packages (from ultralytics) (2.0.17)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\irene\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\irene\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\irene\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\irene\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\irene\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\irene\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\irene\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\irene\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\irene\\anaconda3\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\irene\\anaconda3\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\irene\\anaconda3\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\irene\\anaconda3\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2025.10.5)\n",
      "Requirement already satisfied: filelock in c:\\users\\irene\\anaconda3\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\irene\\anaconda3\\lib\\site-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\irene\\anaconda3\\lib\\site-packages (from torch>=1.8.0->ultralytics) (1.13.3)\n",
      "Requirement already satisfied: networkx in c:\\users\\irene\\anaconda3\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\irene\\anaconda3\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\irene\\anaconda3\\lib\\site-packages (from torch>=1.8.0->ultralytics) (2025.3.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\irene\\anaconda3\\lib\\site-packages (from torch>=1.8.0->ultralytics) (80.9.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\irene\\anaconda3\\lib\\site-packages (from sympy>=1.13.3->torch>=1.8.0->ultralytics) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\irene\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n"
     ]
    }
   ],
   "source": [
    "# programas requeridos\n",
    "!pip install torch\n",
    "!pip install opencv-python\n",
    "!pip install geopandas\n",
    "!pip install ultralytics\n",
    "import torch\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import random\n",
    "import requests\n",
    "import time\n",
    "import geopandas as gpd\n",
    "from tqdm import tqdm\n",
    "from shapely.geometry import Point, Polygon\n",
    "from pyproj import CRS, Geod\n",
    "from math import sqrt\n",
    "from tqdm import tqdm\n",
    "from ultralytics import YOLO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e5da359-cd77-4a24-a67e-81cb979c4d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializaci√≥n\n",
    "### Definimos la carpeta de trabajo\n",
    "path         =  r\"C:\\Users\\irene\\Dropbox\\IBERO\\Clase\"\n",
    "### Definimos la carpeta en la que se encuentra un archivo llamado \"API.txt\" que contiene el API: Literal es lo √∫nico que tiene el archivo\n",
    "path_api     =  r\"C:\\Users\\irene\\Dropbox\\IBERO\\Clase\"\n",
    "\n",
    "### Definimos la carpeta en la que guardar√°n las im√°genes a descargar\n",
    "save_folder  =  'street_view_images'\n",
    "\n",
    "# Leer el API_KEY desde el archivo\n",
    "with open(path_api+ r\"\\\\API_Clase.txt\", \"r\") as file:\n",
    "    API_KEY = file.read().strip()  # Usamos .strip() para eliminar cualquier salto de l√≠nea u espacio adicional\n",
    "\n",
    "# Prefijo para resultados\n",
    "prefijo = \"bd_clase\" # Es el prefijo que se usar√° para guardar la informaci√≥n obtenida de las fotos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4ee29158-f27b-46d9-8d05-ac2e2e611208",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIzaSyA4pvqfHM_M-6wgVAqr3RBkg7e7MN6QBwY\n"
     ]
    }
   ],
   "source": [
    "print(API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dcfb5b60-4513-4dca-a7d7-2e2c5d696775",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ID        lat        lon                  lugar                 coordenadas\n",
      "0   1  19.396921 -99.172481                mi casa  (1, 19.396921, -99.172481)\n",
      "1   2  19.538270 -99.176463    casa de mi tia Rosa   (2, 19.53827, -99.176463)\n",
      "2   3  19.609734 -99.235410  casa de mi tia Georgi   (3, 19.609734, -99.23541)\n"
     ]
    }
   ],
   "source": [
    "# Leer la base de datos\n",
    "df = pd.read_csv(path + r\"\\Base_clase.csv\")\n",
    "df['coordenadas'] = list(zip(df[\"ID\"], df['lat'], df['lon']))\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71b709fe-bbc1-4c36-a12e-ec801e7d2850",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\irene\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\irene\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.get_nearest_street_view(id_hogar, latitud, longitud, radio=10, max_retries=5)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cargamos funciones de busqueda y anl√°isis de imagenes\n",
    "%run ./functions.ipynb\n",
    "get_nearest_street_view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dca8461d-0799-41b6-a9b3-749d81fec7fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîÑ Procesando lugar ID: 1...\n",
      "‚úÖ Encontrado para locaci√≥n 1 en 200 metros (1, 19.396921, -99.172481, 19.39685995249232, -99.17254413479915, 'CpsUYiKm0KWvkMibJWM9fw') \n",
      "\n",
      "üîÑ Procesando lugar ID: 2...\n",
      "‚úÖ Encontrado para locaci√≥n 2 en 200 metros (2, 19.53827, -99.176463, 19.53830428308397, -99.17649601984, 'gHAuHw_Q8xhB9xTFy7aC1A') \n",
      "\n",
      "üîÑ Procesando lugar ID: 3...\n",
      "‚úÖ Encontrado para locaci√≥n 3 en 200 metros (3, 19.609734, -99.23541, 19.60973602189734, -99.23541984989143, '3YCOuPDKyynjSCisqrUmrw') \n"
     ]
    }
   ],
   "source": [
    "# Lista para almacenar los errores\n",
    "errores_list = []\n",
    "# Almacenar resultados\n",
    "fotos_encont = []\n",
    "# Iterar sobre las coordenadas\n",
    "for ID, lat, lon in df['coordenadas']:\n",
    "    print(f\"\\nüîÑ Procesando lugar ID: {ID}...\")\n",
    "    encontrado = None\n",
    "    # Hacemos una b√∫squeda para tener la foto m√°s cercana al punto (200 metros a la redonda)\n",
    "    resultado = get_nearest_street_view(ID, lat, lon, 200, 2)\n",
    "    if resultado:\n",
    "        pano_id, real_lat, real_lon = resultado\n",
    "        encontrado = (ID, lat, lon, real_lat, real_lon, pano_id)\n",
    "        fotos_encont.append(encontrado)\n",
    "        print(f\"‚úÖ Encontrado para locaci√≥n {ID} en 200 metros {encontrado} \")\n",
    "    if not encontrado:\n",
    "        print(f\"‚ùå Hogar {ID}: No se encontr√≥ imagen en 200 metros\")\n",
    "        fotos_encont.append((ID, lat, lon, None, None, None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5622b147-a5b9-494a-814c-522753f9135f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ID        lat        lon   real_lat   real_lon                 pano_id\n",
      "0   1  19.396921 -99.172481  19.396860 -99.172544  CpsUYiKm0KWvkMibJWM9fw\n",
      "1   2  19.538270 -99.176463  19.538304 -99.176496  gHAuHw_Q8xhB9xTFy7aC1A\n",
      "2   3  19.609734 -99.235410  19.609736 -99.235420  3YCOuPDKyynjSCisqrUmrw\n"
     ]
    }
   ],
   "source": [
    "df_resultados = pd.DataFrame(fotos_encont, columns=['ID', 'lat', 'lon', 'real_lat', 'real_lon', 'pano_id'])\n",
    "#df_resultados.to_csv(path + r\"\\resultados_clase.csv\", index=False)\n",
    "print(df_resultados)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ecdb245-747f-40f6-b84b-9e3141168cae",
   "metadata": {},
   "source": [
    "## Paso 3: Descargar imagenes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a936c054-e394-46ed-9d72-4ac91a86a2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leemos el archivo con las observaciones de los hogares\n",
    "df = df_resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3e61be3a-1138-431d-ab78-1fd63908905f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ID        lat        lon   real_lat   real_lon                 pano_id  \\\n",
      "0   1  19.396921 -99.172481  19.396860 -99.172544  CpsUYiKm0KWvkMibJWM9fw   \n",
      "1   2  19.538270 -99.176463  19.538304 -99.176496  gHAuHw_Q8xhB9xTFy7aC1A   \n",
      "2   3  19.609734 -99.235410  19.609736 -99.235420  3YCOuPDKyynjSCisqrUmrw   \n",
      "\n",
      "                         estado_descarga  \n",
      "0  (No descargada, No existe el pano ID)  \n",
      "1  (No descargada, No existe el pano ID)  \n",
      "2  (No descargada, No existe el pano ID)  \n"
     ]
    }
   ],
   "source": [
    "# Quitamos los pano id que generaron problemas ya que inician con \"=\"\n",
    "#df = df_aux[  df_aux[\"pano_id\"] !=\"#¬øNOMBRE?\" ].copy() \n",
    "# Nueva columna para registrar el estado de la descarga\n",
    "df[\"estado_descarga\"] = [(\"No descargada\", \"No existe el pano ID\")] * len(df)  # Inicializa con una tupla repetida para todas las filas\n",
    "#df[\"url\"]= [\"www...\"] * len(df) #inicia string de url para todas las filas\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645c7ab3-4180-449d-af0e-71caa069c570",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterar sobre las filas del DataFrame\n",
    "for index, row in df.iterrows():\n",
    "    print(f\"\\nProcesando observaci√≥n n√∫mero: {index}\")  # A√±ad√≠ un salto de l√≠nea antes\n",
    "    id_hogar = row[\"ID\"]\n",
    "    pano_id = row[\"pano_id\"]\n",
    "    \n",
    "    if pd.notna(pano_id):  # Si hay un pano_id v√°lido\n",
    "        estado, mensaje, url = download_street_view_image(pano_id, ID, save_folder)\n",
    "        df.at[index, \"estado_descarga\"] = (estado, mensaje)  # Asignar la tupla completa\n",
    "        #df.at[index, \"url\"] = url #Guardar url de descarga\n",
    "        \n",
    "# Guardar el nuevo archivo con la columna de descarga\n",
    "df.to_csv(path + r\"\\resultados_clase.csv\", index=False)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9824f2a-d6c8-4ca1-a968-842853c406af",
   "metadata": {},
   "source": [
    "# Paso 4: An√°lisis de Imagenes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42444bfd-2b58-4898-9b77-a12a4bf69786",
   "metadata": {},
   "source": [
    "## YOLO - \"You Only Look Once\"\n",
    "Que es YOLO?\n",
    "Es un algoritmo de detecci√≥n de objetos basado en CNN. Identifica y cuenta objetos en im√°genes.\n",
    "El algoritmo dibuja 'cajas' alrededor de los objetos y les pone una etiqueta.\n",
    "https://colab.research.google.com/github/roboflow-ai/notebooks/blob/main/notebooks/train-yolov8-object-detection-on-custom-dataset.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "613cb5ef-988d-4f38-a89f-942bbd27d607",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando im√°genes:   0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 C:\\Users\\irene\\Dropbox\\IBERO\\Clase\\street_view_images\\1_CpsUYiKm0KWvkMibJWM9fw.jpg: 640x640 4 cars, 191.7ms\n",
      "Speed: 5.8ms preprocess, 191.7ms inference, 10.5ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando im√°genes:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:00<00:00,  2.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 C:\\Users\\irene\\Dropbox\\IBERO\\Clase\\street_view_images\\2_gHAuHw_Q8xhB9xTFy7aC1A.jpg: 640x640 5 cars, 2 trucks, 106.0ms\n",
      "Speed: 4.7ms preprocess, 106.0ms inference, 9.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando im√°genes:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:00<00:00,  4.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 C:\\Users\\irene\\Dropbox\\IBERO\\Clase\\street_view_images\\3_3YCOuPDKyynjSCisqrUmrw.jpg: 640x640 1 car, 101.0ms\n",
      "Speed: 4.8ms preprocess, 101.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando im√°genes: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00,  4.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados guardados en detecciones_objetos_yolov8.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------------\n",
    "# Ejecutar procesamiento de detecci√≥n de objetos\n",
    "# --------------------------------------------------------\n",
    "image_folder = path + r\"\\street_view_images\"\n",
    "\n",
    "image_files = [os.path.join(image_folder, img) for img in os.listdir(image_folder) if img.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "\n",
    "# Llamar a la funci√≥n para procesar las im√°genes solo para detecci√≥n de objetos\n",
    "df_objetos = procesar_imagenes(image_files)\n",
    "\n",
    "# Guardar los resultados en un CSV\n",
    "if not df_objetos.empty:\n",
    "    df_objetos.to_csv(os.path.join(path, prefijo + \"_detecciones_objetos_yolov8.csv\"), index=False)\n",
    "    print(\"Resultados guardados en detecciones_objetos_yolov8.csv\")\n",
    "else:\n",
    "    print(\"No se detectaron objetos en ninguna de las im√°genes.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee811134-6c86-4a17-a17e-d2d653534720",
   "metadata": {},
   "source": [
    "Que obtenemos? Una aproximaci√≥n de cuantos objetos de cada tipo hay en la imagen\n",
    "https://yolov8.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b36c9aec-1afb-4060-b0c9-03b92e7a5a5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>confidence</th>\n",
       "      <th>image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>car</td>\n",
       "      <td>0.854872</td>\n",
       "      <td>1_CpsUYiKm0KWvkMibJWM9fw.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>car</td>\n",
       "      <td>0.732933</td>\n",
       "      <td>1_CpsUYiKm0KWvkMibJWM9fw.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>car</td>\n",
       "      <td>0.528870</td>\n",
       "      <td>1_CpsUYiKm0KWvkMibJWM9fw.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>car</td>\n",
       "      <td>0.365478</td>\n",
       "      <td>1_CpsUYiKm0KWvkMibJWM9fw.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>truck</td>\n",
       "      <td>0.908349</td>\n",
       "      <td>2_gHAuHw_Q8xhB9xTFy7aC1A.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>car</td>\n",
       "      <td>0.841661</td>\n",
       "      <td>2_gHAuHw_Q8xhB9xTFy7aC1A.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>car</td>\n",
       "      <td>0.796518</td>\n",
       "      <td>2_gHAuHw_Q8xhB9xTFy7aC1A.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>car</td>\n",
       "      <td>0.580659</td>\n",
       "      <td>2_gHAuHw_Q8xhB9xTFy7aC1A.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>car</td>\n",
       "      <td>0.553458</td>\n",
       "      <td>2_gHAuHw_Q8xhB9xTFy7aC1A.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>truck</td>\n",
       "      <td>0.535386</td>\n",
       "      <td>2_gHAuHw_Q8xhB9xTFy7aC1A.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>car</td>\n",
       "      <td>0.504611</td>\n",
       "      <td>2_gHAuHw_Q8xhB9xTFy7aC1A.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>car</td>\n",
       "      <td>0.937455</td>\n",
       "      <td>3_3YCOuPDKyynjSCisqrUmrw.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     name  confidence                         image\n",
       "0     car    0.854872  1_CpsUYiKm0KWvkMibJWM9fw.jpg\n",
       "1     car    0.732933  1_CpsUYiKm0KWvkMibJWM9fw.jpg\n",
       "2     car    0.528870  1_CpsUYiKm0KWvkMibJWM9fw.jpg\n",
       "3     car    0.365478  1_CpsUYiKm0KWvkMibJWM9fw.jpg\n",
       "4   truck    0.908349  2_gHAuHw_Q8xhB9xTFy7aC1A.jpg\n",
       "5     car    0.841661  2_gHAuHw_Q8xhB9xTFy7aC1A.jpg\n",
       "6     car    0.796518  2_gHAuHw_Q8xhB9xTFy7aC1A.jpg\n",
       "7     car    0.580659  2_gHAuHw_Q8xhB9xTFy7aC1A.jpg\n",
       "8     car    0.553458  2_gHAuHw_Q8xhB9xTFy7aC1A.jpg\n",
       "9   truck    0.535386  2_gHAuHw_Q8xhB9xTFy7aC1A.jpg\n",
       "10    car    0.504611  2_gHAuHw_Q8xhB9xTFy7aC1A.jpg\n",
       "11    car    0.937455  3_3YCOuPDKyynjSCisqrUmrw.jpg"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_objetos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b87d8835-b544-43f2-82e7-cc801212a8ea",
   "metadata": {},
   "source": [
    "Son datos estructurados o no estructurados?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c92569c-8137-4ebb-8020-f4f903916ad7",
   "metadata": {},
   "source": [
    "## ResNet - \"Resudial Network\"\n",
    "\n",
    "It's a **deep CNN** (152 layers!) that extracts **abstract visual features** from images. Think it as a machine that 'understands' images at a very deep level. It doesn't just see 'a car' or 'a building' - it recognizes complex patterns like 'modern architecture,' 'well-maintained surfaces,' 'color harmony,' and many other subtle visual characteristics that are hard to describe in words.\n",
    "\n",
    "ResNet-152 (Very Deep CNN)            \n",
    "                                      \n",
    "   Layer 1: Detect edges                \n",
    "   Layer 2-10: Detect simple shapes     \n",
    "   Layer 11-50: Detect object parts     \n",
    "   Layer 51-100: Detect whole objects   \n",
    "   Layer 101-152: Detect complex scenes \n",
    "\n",
    "Trained on ImageNet (14 million images, 1000 categories)\n",
    "\n",
    "What we get:\n",
    "A vector of 511 numbers - each number represents an abstract visual feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "46936780-92b0-4a9e-a012-f46e4ffaa441",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extrayendo embeddings: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Proceso terminado. Embeddings guardados en '_embeddings_visuales.csv'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>502</th>\n",
       "      <th>503</th>\n",
       "      <th>504</th>\n",
       "      <th>505</th>\n",
       "      <th>506</th>\n",
       "      <th>507</th>\n",
       "      <th>508</th>\n",
       "      <th>509</th>\n",
       "      <th>510</th>\n",
       "      <th>511</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1_CpsUYiKm0KWvkMibJWM9fw.jpg</td>\n",
       "      <td>0.459005</td>\n",
       "      <td>2.926169</td>\n",
       "      <td>1.299067</td>\n",
       "      <td>0.357865</td>\n",
       "      <td>0.502564</td>\n",
       "      <td>0.337128</td>\n",
       "      <td>1.109234</td>\n",
       "      <td>0.492772</td>\n",
       "      <td>0.440467</td>\n",
       "      <td>...</td>\n",
       "      <td>0.674850</td>\n",
       "      <td>1.653783</td>\n",
       "      <td>0.534376</td>\n",
       "      <td>0.416686</td>\n",
       "      <td>0.117965</td>\n",
       "      <td>1.288140</td>\n",
       "      <td>1.567793</td>\n",
       "      <td>1.494838</td>\n",
       "      <td>0.187128</td>\n",
       "      <td>0.227703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2_gHAuHw_Q8xhB9xTFy7aC1A.jpg</td>\n",
       "      <td>1.287977</td>\n",
       "      <td>2.605522</td>\n",
       "      <td>1.768470</td>\n",
       "      <td>0.468350</td>\n",
       "      <td>0.893737</td>\n",
       "      <td>0.204123</td>\n",
       "      <td>0.325949</td>\n",
       "      <td>0.486919</td>\n",
       "      <td>0.580780</td>\n",
       "      <td>...</td>\n",
       "      <td>0.742258</td>\n",
       "      <td>1.188959</td>\n",
       "      <td>0.457019</td>\n",
       "      <td>1.568733</td>\n",
       "      <td>0.131015</td>\n",
       "      <td>2.111551</td>\n",
       "      <td>0.383693</td>\n",
       "      <td>0.530844</td>\n",
       "      <td>0.538555</td>\n",
       "      <td>0.182467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3_3YCOuPDKyynjSCisqrUmrw.jpg</td>\n",
       "      <td>0.578950</td>\n",
       "      <td>4.447326</td>\n",
       "      <td>2.430570</td>\n",
       "      <td>0.746325</td>\n",
       "      <td>0.816427</td>\n",
       "      <td>0.079238</td>\n",
       "      <td>0.599818</td>\n",
       "      <td>0.006646</td>\n",
       "      <td>0.702534</td>\n",
       "      <td>...</td>\n",
       "      <td>0.148888</td>\n",
       "      <td>1.726836</td>\n",
       "      <td>0.391697</td>\n",
       "      <td>0.594781</td>\n",
       "      <td>0.596333</td>\n",
       "      <td>2.692715</td>\n",
       "      <td>1.074917</td>\n",
       "      <td>1.131631</td>\n",
       "      <td>0.300622</td>\n",
       "      <td>0.700745</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows √ó 513 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          image         0         1         2         3  \\\n",
       "0  1_CpsUYiKm0KWvkMibJWM9fw.jpg  0.459005  2.926169  1.299067  0.357865   \n",
       "1  2_gHAuHw_Q8xhB9xTFy7aC1A.jpg  1.287977  2.605522  1.768470  0.468350   \n",
       "2  3_3YCOuPDKyynjSCisqrUmrw.jpg  0.578950  4.447326  2.430570  0.746325   \n",
       "\n",
       "          4         5         6         7         8  ...       502       503  \\\n",
       "0  0.502564  0.337128  1.109234  0.492772  0.440467  ...  0.674850  1.653783   \n",
       "1  0.893737  0.204123  0.325949  0.486919  0.580780  ...  0.742258  1.188959   \n",
       "2  0.816427  0.079238  0.599818  0.006646  0.702534  ...  0.148888  1.726836   \n",
       "\n",
       "        504       505       506       507       508       509       510  \\\n",
       "0  0.534376  0.416686  0.117965  1.288140  1.567793  1.494838  0.187128   \n",
       "1  0.457019  1.568733  0.131015  2.111551  0.383693  0.530844  0.538555   \n",
       "2  0.391697  0.594781  0.596333  2.692715  1.074917  1.131631  0.300622   \n",
       "\n",
       "        511  \n",
       "0  0.227703  \n",
       "1  0.182467  \n",
       "2  0.700745  \n",
       "\n",
       "[3 rows x 513 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#image_files = [os.path.join(image_folder, f) for f in os.listdir(image_folder)\n",
    "               #if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "\n",
    "df_embeddings = procesar_embeddings_batch(image_files, batch_size=50)\n",
    "\n",
    "# Guardar resultados\n",
    "\n",
    "df_embeddings.to_csv(os.path.join(path,prefijo + \"_embeddings_visuales.csv\"), index=False)\n",
    "\n",
    "print(\"‚úÖ Proceso terminado. Embeddings guardados en '_embeddings_visuales.csv'\")\n",
    "\n",
    "df_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7a1794-1de4-49f2-9c53-e6df24f48e22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3157ca14-6359-4032-8bc1-83ecd0ad4d5c",
   "metadata": {},
   "source": [
    "## Comparison: YOLO vs ResNet\n",
    "\n",
    "| Aspect | YOLO | ResNet |\n",
    "|--------|------|--------|\n",
    "| **Purpose** | Count specific objects | Extract abstract features |\n",
    "| **Output** | Numbers of objects (car: 5, person: 2) | 511 abstract numbers |\n",
    "| **Interpretable?** | ‚úÖ YES (we know what each number means) | ‚ùå NO (abstract, learned features) |\n",
    "| **Example** | \"maybe 5 cars, maybe 2 people\" | \"[0.23, 0.91, 0.05, ...]\" |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3cab6eb-8422-45e8-b4e3-579d9ae53fd8",
   "metadata": {},
   "source": [
    "## Porcentaje de verde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5bbb6856-415c-45d3-94a6-9ea0380e6fc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando porcentaje de verde: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00, 86.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proceso terminado. El archivo 'porcentaje_verde.csv' ha sido guardado.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Procesamos las im√°genes para obtener el porcentaje de verde\n",
    "df_verde = procesar_porcentaje_verde(image_files)\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Guardar los resultados en un CSV\n",
    "# --------------------------------------------------------\n",
    "df_verde.to_csv(os.path.join(path, prefijo +\"_porcentaje_verde.csv\"), index=False)\n",
    "\n",
    "print(\"Proceso terminado. El archivo 'porcentaje_verde.csv' ha sido guardado.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6fa47ad2-5733-467d-bfc6-f259642721b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>porcentaje_verde</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1_CpsUYiKm0KWvkMibJWM9fw.jpg</td>\n",
       "      <td>0.056049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2_gHAuHw_Q8xhB9xTFy7aC1A.jpg</td>\n",
       "      <td>0.099449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3_3YCOuPDKyynjSCisqrUmrw.jpg</td>\n",
       "      <td>0.062283</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          image  porcentaje_verde\n",
       "0  1_CpsUYiKm0KWvkMibJWM9fw.jpg          0.056049\n",
       "1  2_gHAuHw_Q8xhB9xTFy7aC1A.jpg          0.099449\n",
       "2  3_3YCOuPDKyynjSCisqrUmrw.jpg          0.062283"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_verde"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb37a9e-3ef5-4b80-a32b-28e8bd8e7f28",
   "metadata": {},
   "source": [
    "Que obtenemos? Porcentaje de pixeles verdes en una imagen.\n",
    "Para reflexionar: Que podemos hacer con esta informaci√≥n? que preguntas de investigaci√≥n se les ocurren esta informaci√≥n sea relevante?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e40be716-3181-451f-8c3d-d490b1c90c6b",
   "metadata": {},
   "source": [
    "## Reflexi√≥n para el martes (Entregar a Isidro)\n",
    "\n",
    "1. Porque escogiste esos cinco lugares?\n",
    "2. Que puedes observar en la fotos? que tan parecidas o diferentes son entre ellas?\n",
    "3. Como puedes interpretar los resultados del modelo YOLO?\n",
    "4. Crees que el modelo YOLO hizo un buen trabajo comparado a lo que tu estas observando? Si, No, porque?\n",
    "5. Puedes interpretar los resultados del modelo ResNet? Porque si o porque no? Puedes inferir algo de los resultados de este modelo?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f544a59-453f-4db3-b998-5e7cff71911e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
