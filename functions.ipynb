{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c90430c1-0556-494d-b64a-e7d250f9b4a7",
   "metadata": {},
   "source": [
    "# Functions to analyze Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1a3e00-263e-4a7b-89b5-91ea1c0cf6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from ultralytics import YOLO\n",
    "import numpy as np\n",
    "import cv2\n",
    "import gc\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3cbb9d2-5d6e-4579-9ff9-7dedac54edac",
   "metadata": {},
   "source": [
    "# Función para encontrar foto de hogar Original en la carpeta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1535f6cf-badd-42f1-bb65-18681f0d991f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to find an image file that matches the search term\n",
    "def find_matching_image(search_term, images_folder):\n",
    "    # Common image file extensions\n",
    "    image_extensions = ['.jpg', '.jpeg', '.png', '.gif', '.bmp', '.tiff']\n",
    "    \n",
    "    # Convert search term to lowercase for case-insensitive matching\n",
    "    search_term_lower = search_term.lower()\n",
    "    \n",
    "    # List all files in the directory\n",
    "    for file in os.listdir(images_folder):\n",
    "        file_lower = file.lower()\n",
    "        \n",
    "        # Check if the file is an image and matches the search term\n",
    "        if any(file_lower.endswith(ext) for ext in image_extensions):\n",
    "            \n",
    "            # Match with the filename (without extension)\n",
    "            if os.path.splitext(file_lower)[0] == search_term_lower:\n",
    "                return os.path.join(images_folder, file)\n",
    "\n",
    "    \n",
    "    # No matching image found\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5195d0b-c396-48d0-ba43-145d0b47793e",
   "metadata": {},
   "source": [
    "## YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c267728-dcb5-4d94-beed-869b9f463181",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# Cargar modelo YOLOv8\n",
    "# --------------------------------------------------------\n",
    "model = YOLO(\"yolov8n.pt\")  # Usamos el modelo más ligero\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Función para detección de objetos con YOLOv8\n",
    "# --------------------------------------------------------\n",
    "def detect_objects(image_path):\n",
    "    try:\n",
    "        results = model(image_path)\n",
    "        detections = results[0].boxes.data.cpu().numpy()\n",
    "        \n",
    "        if detections.size == 0:\n",
    "            return pd.DataFrame(columns=['name', 'confidence', 'image'])\n",
    "\n",
    "        df_results = pd.DataFrame(detections, columns=['xmin', 'ymin', 'xmax', 'ymax', 'confidence', 'class'])\n",
    "        df_results['name'] = df_results['class'].apply(lambda x: model.names[int(x)])\n",
    "        df_results['image'] = os.path.basename(image_path)\n",
    "        return df_results[['name', 'confidence', 'image']]\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error en {image_path}: {e}\")\n",
    "        return pd.DataFrame(columns=['name', 'confidence', 'image'])\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Función para procesar imágenes de manera secuencial\n",
    "# --------------------------------------------------------\n",
    "def procesar_imagenes(image_files):\n",
    "    resultados_objetos = []\n",
    "    \n",
    "    # Procesar las imágenes una por una\n",
    "    for image_path in tqdm(image_files, desc=\"Procesando imágenes\"):\n",
    "        # Realizar detección de objetos\n",
    "        df_obj = detect_objects(image_path)\n",
    "        \n",
    "        if not df_obj.empty:\n",
    "            resultados_objetos.append(df_obj)\n",
    "    \n",
    "    # Combinar los resultados de detección\n",
    "    if resultados_objetos:\n",
    "        df_objetos = pd.concat(resultados_objetos, ignore_index=True)\n",
    "        return df_objetos\n",
    "    else:\n",
    "        return pd.DataFrame(columns=['name', 'confidence', 'image'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4b92c2-411c-4565-b1b5-6f3d6de2558e",
   "metadata": {},
   "source": [
    "# Porcentaje Verde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6823193d-7725-4bc9-afc1-b7b33144b701",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# Función para calcular porcentaje de verde en la imagen\n",
    "# --------------------------------------------------------\n",
    "def porcentaje_verde(image_path):\n",
    "    try:\n",
    "        # Leemos la imagen\n",
    "        img = cv2.imread(image_path)\n",
    "        \n",
    "        # Verificamos si la imagen es válida\n",
    "        if img is None:\n",
    "            print(f\"Error: No se pudo leer la imagen {image_path}\")\n",
    "            return np.nan\n",
    "        \n",
    "        # Reducimos la resolución para reducir uso de memoria\n",
    "        img = cv2.resize(img, (512, 512))\n",
    "        \n",
    "        # Convertimos la imagen a formato HSV\n",
    "        hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "        \n",
    "        # Definimos el rango de verde en el espacio HSV\n",
    "        lower = np.array([35, 40, 40])  # Rango inferior para verde\n",
    "        upper = np.array([85, 255, 255])  # Rango superior para verde\n",
    "        \n",
    "        # Creamos una máscara con los valores dentro del rango de verde\n",
    "        mask = cv2.inRange(hsv, lower, upper)\n",
    "        \n",
    "        # Calculamos el porcentaje de píxeles verdes\n",
    "        verde_percentage = np.sum(mask > 0) / mask.size\n",
    "        return verde_percentage\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error en porcentaje_verde para {image_path}: {e}\")\n",
    "        return np.nan\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Función para procesar las imágenes una por una\n",
    "# --------------------------------------------------------\n",
    "def procesar_porcentaje_verde(image_files):\n",
    "    resultados_verde = []\n",
    "    \n",
    "    for image_path in tqdm(image_files, desc=\"Procesando porcentaje de verde\"):\n",
    "        verde = porcentaje_verde(image_path)\n",
    "        resultados_verde.append(verde)\n",
    "    \n",
    "    # Extraer solo el nombre del archivo y crear DataFrame\n",
    "    image_names = [os.path.basename(img) for img in image_files]\n",
    "    # Crear DataFrame para los resultados\n",
    "    df_verde = pd.DataFrame({'image': image_names, 'porcentaje_verde': resultados_verde})\n",
    "    return df_verde"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce651b2-a078-419d-b4bc-96d3b6831b93",
   "metadata": {},
   "source": [
    "# Textura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe616936-9e93-4041-b0ce-0e9008ec9ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# FUNCIÓN: Calcula nivel de textura con gradiente (liviana)\n",
    "# --------------------------------------------------------\n",
    "def nivel_textura_gradiente(image_path):\n",
    "    try:\n",
    "        # Cargar en escala de grises\n",
    "        img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "        if img is None:\n",
    "            print(f\"No se pudo leer: {image_path}\")\n",
    "            return np.nan\n",
    "\n",
    "        # Redimensionar para ahorrar memoria\n",
    "        img = cv2.resize(img, (256, 256))\n",
    "\n",
    "        # Gradientes en X y Y con Sobel\n",
    "        grad_x = cv2.Sobel(img, cv2.CV_64F, 1, 0, ksize=3)\n",
    "        grad_y = cv2.Sobel(img, cv2.CV_64F, 0, 1, ksize=3)\n",
    "\n",
    "        # Magnitud del gradiente\n",
    "        grad_magnitude = np.sqrt(grad_x**2 + grad_y**2)\n",
    "\n",
    "        # Desvío estándar como medida de textura\n",
    "        texture_score = np.std(grad_magnitude)\n",
    "        return texture_score\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error en {image_path}: {e}\")\n",
    "        return np.nan\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# FUNCIÓN: Procesa imágenes por lotes\n",
    "# --------------------------------------------------------\n",
    "def procesar_textura_batch(image_files, batch_size=50):\n",
    "    resultados_textura = []\n",
    "    for i in tqdm(range(0, len(image_files), batch_size), desc=\"Calculando textura\"):\n",
    "        batch = image_files[i:i+batch_size]\n",
    "        for img_path in batch:\n",
    "            textura = nivel_textura_gradiente(img_path)\n",
    "            resultados_textura.append(textura)\n",
    "        gc.collect()\n",
    "    # Extraer solo el nombre del archivo y crear DataFrame\n",
    "    image_names = [os.path.basename(img) for img in image_files]\n",
    "    return pd.DataFrame({'image': image_names, 'nivel_textura': resultados_textura})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80da487f-1097-425d-b83f-dda9d7b5051d",
   "metadata": {},
   "source": [
    "# Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea04a03-61bb-4c1e-b01e-ad16c471c1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --------------------------------------------------------\n",
    "# Cargar modelo preentrenado (ResNet18 sin la capa final)\n",
    "# --------------------------------------------------------\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "resnet = models.resnet18(pretrained=True)\n",
    "resnet = torch.nn.Sequential(*list(resnet.children())[:-1])  # Quitar capa de clasificación\n",
    "resnet.eval().to(device)\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Transformación de imágenes para ResNet\n",
    "# --------------------------------------------------------\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Tamaño requerido por ResNet\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Función para extraer embedding visual\n",
    "# --------------------------------------------------------\n",
    "def extraer_embedding(image_path):\n",
    "    try:\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        image_tensor = transform(image).unsqueeze(0).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            embedding = resnet(image_tensor)\n",
    "            embedding = embedding.squeeze().cpu().numpy()  # shape: (512,)\n",
    "        return embedding\n",
    "    except Exception as e:\n",
    "        print(f\"Error en {image_path}: {e}\")\n",
    "        return [float('nan')] * 512\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Función para procesar imágenes por lotes\n",
    "# --------------------------------------------------------\n",
    "def procesar_embeddings_batch(image_files, batch_size=50):\n",
    "    embeddings = []\n",
    "    nombres = []\n",
    "\n",
    "    for i in tqdm(range(0, len(image_files), batch_size), desc=\"Extrayendo embeddings\"):\n",
    "        batch = image_files[i:i+batch_size]\n",
    "        for img_path in batch:\n",
    "            emb = extraer_embedding(img_path)\n",
    "            embeddings.append(emb)\n",
    "            nombres.append(img_path)\n",
    "        gc.collect()\n",
    "    # Extraer solo el nombre del archivo y crear DataFrame\n",
    "    image_names = [os.path.basename(img) for img in nombres]\n",
    "    df = pd.DataFrame(embeddings)\n",
    "    df.insert(0, \"image\", image_names)\n",
    "    return df\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
